{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rigid registration of atomic resolution STEM data \n",
    "This notebook walks through using the rigidregistration python package to register quickly acquired frames to one another to generate a high signal to noise image with reduced scan artifacts. For more detail on the technique, see **\"Image registration of low signal-to-noise cryo-STEM data\"**, Ultramicroscopy (2018), [DOI: 10.1016/j.ultramic.2018.04.008](https://doi.org/10.1016/j.ultramic.2018.04.008)\n",
    "\n",
    "A high level overview of the process is:\n",
    "1) Data is loaded and inspected\n",
    "\n",
    "2) Frames are Fourier filtered to weight information as a function of spatial frequency, in order to improve evaluation of shifts between images.\n",
    "\n",
    "3) Every frame in the stack is cross correlated with every other frame to measure the shift between them (the position of the maximum in the cross correlation). \n",
    "\n",
    "4) Incorrect shifts are identified by evaluating transitivity / identifying outliers, and corrected by enforcing transitivity or omitting images/cross correlations.\n",
    "\n",
    "5) Images are translated to eliminate relative shifts, frames are averaged along the stacking axis to yield a high signal to noise average image.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting started\n",
    "\n",
    "These first few cells below are preparatory: importing the necessary python libraries and functions, loading and pre-inspecting the data, and instantiating (creating) the 'imstack' object, which contains most of the functions that will be used.\n",
    "\n",
    "In this example, data which is formatted as **.tif files** are loaded using the `tifffile package`.  For other file formats common to electron microscopy data (e.g., .dm3, .ser...) `hyperspy` or `ncempy` can be used to read in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries and functions\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "from tifffile import imread\n",
    "import rigidregistration\n",
    "\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data.  \n",
    "# Final axis of stack variable should iterate over images.\n",
    "# For best performance, data should be normalized between 0 and 1\n",
    "\n",
    "f=\"../Data/BSCMO_0047 3.7 Mx_0.tif\"        # Filepath to data \n",
    "stack=np.rollaxis(imread(f),0,3)           # Rearrange axes so final axis iterates over images\n",
    "stack = stack - stack.min()\n",
    "stack=stack[:,:,:]/stack.max()             # Normalize data between 0 and 1\n",
    "print(\"Analyzing {}.\".format(f))\n",
    "print(\"Shape: {}.\".format(str(stack.shape)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect data in preparation for registration\n",
    "# On the left is a single frame of the stack, on the right is the FFT of the frame\n",
    "\n",
    "for i in range(5,6):                      # Select which images from the stack to display\n",
    "    fig,(ax1,ax2)=plt.subplots(1,2,figsize=(8,4))\n",
    "    ax1.matshow(stack[:,:,i],cmap='gray')\n",
    "    ax2.matshow(np.log(np.abs(np.fft.fftshift(np.fft.fft2(stack[:,:,i])))+1e-9),cmap='gray',vmin=np.average(np.log(np.abs(np.fft.fft2(stack[:,:,i]))))) \n",
    "    ax1.grid(False)\n",
    "    ax2.grid(False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate imstack object, and get all FFTs\n",
    "\n",
    "s=rigidregistration.stackregistration.imstack(stack)    # Instantiage imstack object.\n",
    "s.getFFTs()                                             # Calculate the FFTs of each image in the stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Fourier masking\n",
    "Select a Fourier mask, defining which information will be weighted more or less to calculate the image shifts. \n",
    "**There are two choices to be made:** <span style=\"color:orange\"> the cutoff frequency </span>and <span style=\"color:orange\"> mask shape</span>. It is also possible to define a unique Fourier mask.\n",
    "\n",
    "**1. The cutoff frequency**\n",
    "\n",
    "In all cases, the parameter ***`n`*** controls the mask cutoff frequency; features smaller than ~n pixels will be ignored during image correlation.\n",
    "For data with higher SNR, choosing a mask with n at the information limit is frequently sufficient.\n",
    "For low-SNR data, choosing a mask with a cutoff frequency near the primary Bragg peaks is often preferable, as this heavily weights low frequency information to avoid unit-cell hops, but ideally contains just enough lattice information to 'lock-in' to the lattice.\n",
    "\n",
    "**2. The mask shape**\n",
    "\n",
    "Supported apodization functions for makeFourierMask() method are `\"bandpass\", \"lowpass\", \"hann\", \"hamming\", \"blackman\", \"gaussian\", \"none\"`.\n",
    "For lattices lacking high rotational symmetry, an anisotropic mask is generally preferable to avoid overweighting one lattice direction, discussed further below.\n",
    "Details functional forms can be found in the source code.\n",
    "\n",
    "**3. Defining a unique mask**\n",
    "\n",
    "The imstack object contains several meshgrids which correspond to Fourier space coordinates, facilitating defining a unique Fourier mask.  See below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Explore mask shape options\n",
    "\n",
    "# The displayed plots are:\n",
    "# Left: The full FFT in black and white, with a colored, semitransparent overlay showing the mask\n",
    "# Middle: The FFT multiplied by the weighting mask\n",
    "# Right: The cross correlation of a selected pair of images, weighted by the chosen mask\n",
    "\n",
    "\n",
    "masktypes=[\"bandpass\",\"hann\",\"none\"]   # List of mask shapes\n",
    "\n",
    "# other options include \"lowpass\", \"hamming\", \"blackman\", \"gaussian\"\n",
    "\n",
    "n=4                                                                              # Set cutoff frequency\n",
    "\n",
    "i,j = 5,9                                    # Choose image pair to cross correlate. \n",
    "for masktype in masktypes:                   # Iterate over mask types\n",
    "    s.makeFourierMask(mask=masktype,n=n)     # Set the selected Fourier mask\n",
    "    s.show_Fourier_mask(i=i,j=j)             # Display results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vary n, the cutoff frequency\n",
    "\n",
    "# In a typical workflow, this parameter is varied and the effect on the cross correlation is optimized\n",
    "\n",
    "masktype=\"hann\"\n",
    "\n",
    "i,j = 5,9                                    # Choose image pair\n",
    "for n in np.arange(2,10,4):                  # Select n values to test\n",
    "    s.makeFourierMask(mask=masktype,n=n)     # Set the selected Fourier mask\n",
    "    s.show_Fourier_mask(i=i,j=j)             # Display the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elliptical Gaussian masks\n",
    "\n",
    "# The makeFourierMask_eg() method creates an elliptical gaussian mask, with parameters n1, n2, and theta.\n",
    "# n1, n2 define the cutoff frequencies along the two primary axes \n",
    "# theta defines the mask tilt, in degrees.\n",
    "\n",
    "n1=6\n",
    "n2=2\n",
    "theta=60\n",
    "i,j = 1,10\n",
    "s.makeFourierMask_eg(n1=n1,n2=n2,theta=np.radians(theta))   # Set the selected mask\n",
    "s.show_Fourier_mask(i=i,j=j)                                # Display the results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a final mask to use. For most datasets a <span style=\"color:red\">hann mask</span> with a carefully chosen width (n) can work well. For structures with very different lattice parameters (such as BSCCO) an elliptical mask may work better, in which case you can use the <span style=\"color:red\">s.makeFourierMask_eg</span> function as above and pass in an <span style=\"color:red\">n1, n2, and theta</span>.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# input your final mask parameters here and run this cell before moving on to calculating the image shifts\n",
    "\n",
    "masktype=\"hann\"\n",
    "\n",
    "i,j = 5,9                                    # Choose image pair\n",
    "n =??                                        # Select n value\n",
    "s.makeFourierMask(mask=masktype,n=n)         # Set the selected Fourier mask\n",
    "s.show_Fourier_mask(i=i,j=j)                 # Display the results\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\">Checkpoint:</span>\n",
    "Compare your selected masks and resulting cross correlations with your group -- why did you choose the mask you did? What features did you look for in the FFT and the cross correlation to make this choice?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Calculate image shifts\n",
    "Calculate the relative shifts between all pairs of images from their cross correlations.\n",
    "\n",
    "Analytically, for two functions which are identical except for some shift, the shift is given by the maximum value of their cross correlation.\n",
    "After calculating the cross correlation, here it's maximum may be found in one of two ways: finding the brightest pixel, or fitting gaussian functions.  Which method is used is controlled by the findMaxima parameter.\n",
    "\n",
    "#### 1. Brightest pixel \n",
    "\n",
    "The shift is given directly by the position of the brightest pixel in the cross correlation.  This is the fastest approach, and is selected by setting ***`findMaxima`***=<span style=\"color:orange\">\"pixel\"</span>.  In this approach, the relative shifts are determined with resolution of 1 pixel; however, the final shifts which are applied to the images before averaging will be determined using all of the relative image shifts between all pairs of images, thus the final shifts may still be determined with subpixel resolution, with an accuracy that generally improves with the number of images in the stack.\n",
    "\n",
    "#### 2. Gaussian fitting \n",
    "\n",
    "Fitting a continuous function to the maximum of the cross correlation is a simple way to find the shift between an image pair with subpixel resolution.  For images of atomic lattices, a Gaussian is a natural choice for a fitting function.\n",
    "\n",
    "For images of crystal lattices, 'unit cell hop' errors can occur, wherein the calculated shift between a pair of images is incorrect by a multiple of the primitive lattice vectors.  Unit cell hops become increasingly common due to sampling error when the real space sampling of the image is low enough that each atomic column is only a handful of pixels across.  Fitting a continuous function can correct for this sampling error, by performing Gaussian fits to several regions near the brighest several pixels, and then finding the cross correlation maximum using these continuous fits.\n",
    "\n",
    "This method is selected by setting ***`findMaxima`***=<span style=\"color:orange\">\"gf\"</span>.  Before running the Gaussian fitting method, three additional parameters for the fitting should be set by calling s.setGaussianFitParams().  These are:\n",
    "\n",
    "  * ***`sigma_guess`***: sets the initial guess for the standard deviation of the guassian fits, in pixels.  This may be estimated simply and quickly by observing the peak widths in the cross correlations or the width of atomic columns in the raw data.\n",
    "\n",
    "  * ***`window_radius`***: sets the size of the region about the brightest pixel which is used to fit a gaussian.  Should be set such that neighboring cross correlation peaks are excluded; the window used is a square region of size length **2xwindow_radius+1**.\n",
    "\n",
    "  * ***`num_peaks`***: sets how many of the brightest pixels to fit gaussians to. Typically **3-5** are sufficient to handle sampling problems. \n",
    "  \n",
    "#### For most  datasets using gaussian fits will yield a higher quality registration with only a modest amount of additional time required. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Values for <span style=\"color:red\">sigma_guess, window_radius</span> should be set based on the size of the peaks in the cross correlation.\n",
    "\n",
    "This cell will take 1-3 minutes to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate image shifts using gaussian fitting to get subpixel precision in each fit\n",
    "# Be sure to see parameter descriptions above! The fits can take some time. \n",
    "# If you want to make sure things are progressing, set verbose to True to get a message after each shift\n",
    "\n",
    "findMaxima = 'gf'\n",
    "s.setGaussianFitParams(num_peaks=3,sigma_guess= ??,window_radius= ??)\n",
    "\n",
    "t0=time()                                                  # Start time \n",
    "s.findImageShifts(findMaxima=findMaxima,verbose=False)     # Find shifts.  \n",
    "t=time()-t0                                                # End time\n",
    "print(\"Performed {} correlations in {} minutes {} seconds\".format(int(s.nz*(s.nz-1)/2),int(t/60),t%60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find and correct outliers in shift matrix\n",
    "The previous step determines the relative shifts between all pairs of images.  Here, any incorrectly calculated shifts -- which may result from noisy, low SNR data -- are identified and corrected.  First, the shift matrix is displayed and inspected.  Next, outliers are identified.  Outliers are then corrected.\n",
    "\n",
    "**1. Display the shift matrix**\n",
    "\n",
    "For a stack of $N$ images, there are $N-1$ relative shifts for each image.  The complete set of relative shifts is stored in an $NxN$ matrix.  Element $i,j$ of the shift matrix gives the relative shift of image $i$ with respect to image $j$.<sup>1</sup>  To be physically consistent, the relative image shifts must add vectorially, i.e. $\\mathbf{r}_{ij} + \\mathbf{r}_{jk} = \\mathbf{r}_{ik}$.  In this step, we enforce physical consistency in the shift matrix.  Visually, a correct shift matrix should appear \"smooth\" (though not necessarily varying monotonically).\n",
    "\n",
    "**2. Identify outliers**\n",
    "\n",
    "Several approaches are possible to identify outliers in the shift matrix.  \n",
    "\n",
    "The recommended method is by enforcing transitivity, using `s.get_outliers()`.  There is one required parameter and one optional parameter.  The required parameter is a <span style=\"color:orange\">threshhold</span> value - higher threshhold values permit greater deviations from perfect transitivity.  The optional parameter <span style=\"color:orange\">maxpaths</span> is the number of transitivity relationships used to evaluate a given relative image shift - for example, $\\mathbf{r}_{12} + \\mathbf{r}_{24} = \\mathbf{r}_{14}$ and $\\mathbf{r}_{13} + \\mathbf{r}_{34} = \\mathbf{r}_{14}$ are two distinct transitivity relationships that can be used to evaluate the self consistency of the relative image shift from image 1 to image 4.\n",
    "\n",
    "A simpler method to detect outliers is to require that each matrix element does not differ but too great an amount from its nearest neighbor elements, which roughly corresponds to enforcing the the shift matrix is \"smooth\".  The single required paramater is a <span style=\"color:orange\">threshold</span> value.\n",
    "\n",
    "Finally, if necessary, outliers can be directly identified manually.\n",
    "\n",
    "**3. Correct outliers**\n",
    "\n",
    "Outliers are corrected by extrapolating the correct values of any identified outliers using the transistivity relations.\n",
    "\n",
    "\n",
    "<sup>1</sup>  But who needs ImageJ, amirite?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show Xij and Yij matrices\n",
    "s.show_Rij()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify outliers by enforcing transitivity, using additional optional features\n",
    "\n",
    "# For many datasets if filtering and fit parameters were selected well above no outliers will be present\n",
    "# For others, particularly at cryo, even perfect parameter selection will still have some outliers\n",
    "# For this tutorial, the BSCMO dataset can have no outliers, while the BSCCO cryo dataset will always have some\n",
    "\n",
    "s.set_bad_images([])                             # Flag entire images (rows/columns of shift matrix) as unuseable\n",
    "                                                 # Passing in an empty list [] will use every image\n",
    "\n",
    "\n",
    "s.get_outliers(threshold=??,maxpaths=??)       # Set outlier threshhold and maxpaths\n",
    "                                               # 10 for both parameters is a reasonable starting point,\n",
    "                                               # decrease threshold to mask more pairs, and increase to mask fewer\n",
    "                                               # 10 maxpaths is normally sufficient but increase to improve \n",
    "                                               # transitivity assessment\n",
    "\n",
    "\n",
    "\n",
    "s.show_Rij(mask=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are having trouble identifying outliers with transitivity above, you can use this cell to identify outliers using nearest neighbors to enforce \"smoothness.\" Be careful -- this is a more error prone method of outlier identification,\n",
    "<b>so only run it if you are not able to identify the outliers using transitivity</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify outliers using nearest neighbors to enforce \"smoothness\"\n",
    "# Can be useful if transitivity doesn't correctly identify outliers\n",
    "\n",
    "s.set_bad_images([])                           # Flag entire images (rows/columns of shift matrix) as unuseable\n",
    "\n",
    "\n",
    "s.get_outliers_NN(max_shift= ??)                 # Set outlier threshhold and maxpaths\n",
    "\n",
    "\n",
    "s.show_Rij(mask=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct outliers\n",
    "\n",
    "s.make_corrected_Rij()    # Correct outliers using the transitivity relations\n",
    "s.show_Rij_c()            # Display the corrected shift matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\">Checkpoint:</span>\n",
    "Compare your original and corrected shift matrices with your group.  Are your original (uncorrected) matrices similar to your group members? How did different parameter choices for the masks and gaussian fits affect the matrices, and what seemed to work best? \n",
    "\n",
    "Why are the shift matrices symmetric across the diagonal? What is different about the X vs Y shift matrix? What does this tell you about the sample's drift?\n",
    "\n",
    "For outlier identification and correction, what methods were used / what parameters seemed to work best? Did you set any bad images? Were the final corrected shift matrices similar?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate average image\n",
    "\n",
    "To obtain the average image, each image in the stack is shifted by an amount which is calculated from the shift matrix.  The entire, shifted image stack is then averaged.  Several functions are available for displaying and saving the resulting average image, and for summarizing the processing that's been applied to the data for quick review.\n",
    "\n",
    "**1. Shifting and averaging**\n",
    "\n",
    "The final shifts which are applied to each image in the stack are determined by averaging each row of the shift matrix, i.e. the shift applied to the $i$'th image is \n",
    "\n",
    "$\\mathbf{r}_i = \\frac{1}{N}\\sum_{j}\\mathbf{R}_{ij}$\n",
    "\n",
    "Shifts are applied in Fourier space using the shift theorem.  Running `s.get_average_image()` calculates the shifts, shifts the images, and calculates the average image.  The final shifts which have been applied to the data are stored in ***`s.shifts_x`*** and ***`s.shifts_y`***, and the shifted image stack is stored in ***`s.stack_registered`***.\n",
    "\n",
    "**2. Displaying and saving reports and averaged images**\n",
    "\n",
    "The averaged image can be displayed and saved by running `s.show()` and `s.save()`, respectively.\n",
    "A summary of all the processing that's been performed on the data can be displayed and saved by running `s.show_report()` and `s.save_report()`, respectively.  Saving a report is highly recommended, as it allows quick assessment of the fidelity of the final images.\n",
    "\n",
    "The `s.save()` method saves a .tif file of the average image.  Metadata with the processing parameters used to create the average image are stored in the description string of the .tif file.\n",
    "\n",
    "Note that because images have been shifted, a region about the edges of the final image will no longer be meaningful and should be discarded.  The `s.save()` method automatically discards unmeaningful edge data.  To keep the full field of view in the final output, pass the key:`value pair crop=False` to `s.save()`.  In this case, be sure to exclude the edge region from any final analysis.  The min/max values delineating meaningful data are stored as ***`s.xmin`***, ***`s.xmax`***, ***`s.ymin`***, and ***`s.ymax`***."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create registered image stack and average\n",
    "\n",
    "# This cell may take a minute to run\n",
    "\n",
    "s.get_averaged_image()   # To skip calculation of image shifts, or correcting the shift matrix, pass the function\n",
    "                         # get_shifts=False, or correct_Rij=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display final image\n",
    "\n",
    "s.show()                 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\">Checkpoint:</span>\n",
    "Compare your averaged images and Fourier transforms with the group. Do all of them look similar? What could be the cause of any differences? Be sure to zoom in and compare the averaged image and fourier transform with the single frame from the start of the notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the average image as a Tiff to the same directory the stack was in, with _registered added to the filename\n",
    "\n",
    "s.save(f[:-4]+\"_registered.tif\")     # To keep the image uncropped, use crop=False.  The appropriate \n",
    "                                                # cropping boundaries are stored as metadata in the description string\n",
    "                                                # of the output .tif file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save report of registration procedure\n",
    "\n",
    "s.save_report(f[:-4]+\"_sample_report.pdf\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
